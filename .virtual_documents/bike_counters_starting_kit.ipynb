


from pathlib import Path

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import sklearn


data_train = pd.read_parquet(Path("/Users/smesguiche/bike_counters_Samuel/data/train.parquet"))


data_train





data_train.info()





data_train.nunique(axis=0)





data_train.groupby(["site_name", "counter_name"], observed=True)["log_bike_count"].sum().sort_values(ascending = False).to_frame()





import folium

m = folium.Map(location=data_train[["latitude", "longitude"]].mean(axis=0), zoom_start=13)

for _, row in (
    data_train[["counter_name", "latitude", "longitude"]]
    .drop_duplicates("counter_name")
    .iterrows()
):
    folium.Marker(
        row[["latitude", "longitude"]].values.tolist(), popup=row["counter_name"]
    ).add_to(m)

m





#mask = data_train["counter_name"] == "Totem 73 boulevard de Sébastopol S-N"

#data_train[mask].plot(x="date", y="bike_count")





mask = data_train["counter_name"] == "Totem 73 boulevard de Sébastopol S-N"

data_train[mask].groupby(pd.Grouper(freq="1w", key="date"))[["bike_count"]].sum().plot()


# We want to aggregate more counters on the same plot, we think that 7 is a good number to observe a trend.
# Find the top 10 counters by total bike count
top_counters = data_train.groupby("counter_name", observed = True)["bike_count"].sum().nlargest(7).index

# Create a mask for these top counters
mask = data_train["counter_name"].isin(top_counters)

# Group by week and plot
data_train[mask].groupby(["counter_name", pd.Grouper(freq="1w", key="date")], observed = True)["bike_count"].sum().unstack(0).plot(figsize = (12,6), legend = 'upper right')










fig, ax = plt.subplots(figsize=(10, 4))

mask = (
    (data_train["counter_name"] == "27 quai de la Tournelle SE-NO")
    & (data_train["date"] > pd.to_datetime("2021/06/01"))
    & (data_train["date"] < pd.to_datetime("2021/06/08"))
)

data_train[mask].plot(x="date", y="bike_count", ax=ax)





top_counters = data_train.groupby("counter_name", observed = True)["bike_count"].sum().nlargest(4).index

# Time frame
start_date = pd.to_datetime("2021/03/01")
end_date = pd.to_datetime("2021/03/08")

# Initialize plot
fig, ax = plt.subplots(figsize=(12, 6))

# Plot each of the top counters
for counter in top_counters:
    mask = (
        (data_train["counter_name"] == counter) &
        (data_train["date"] > start_date) &
        (data_train["date"] < end_date)
    )
    data_train[mask].plot(x="date", y="bike_count", ax=ax, label=counter)

# Customize the plot
plt.legend(fontsize='small')
plt.show()






import seaborn as sns


ax = sns.histplot(data_train, x="bike_count", kde=True, bins=50)





ax = sns.histplot(data_train, x="log_bike_count", kde=True, bins=50)








def _encode_dates(X):
    X = X.copy()  # modify a copy of X
    # Encode the date information from the DateOfDeparture columns
    X.loc[:, "year"] = X["date"].dt.year
    X.loc[:, "month"] = X["date"].dt.month
    X.loc[:, "day"] = X["date"].dt.day
    X.loc[:, "weekday"] = X["date"].dt.weekday
    X.loc[:, "hour"] = X["date"].dt.hour

    # Finally we can drop the original columns from the dataframe
    return X.drop(columns=["date"])


data_train["date"].head()


_encode_dates(data_train[["date"]])





from sklearn.preprocessing import FunctionTransformer

date_encoder = FunctionTransformer(_encode_dates, validate=False)
date_encoder.fit_transform(data_train[["date"]]).head()





from sklearn.preprocessing import OneHotEncoder

enc = OneHotEncoder(sparse_output=False)

enc.fit_transform(_encode_dates(data_train[["date"]])[["hour"]].head())








data_test = pd.read_parquet(Path("/Users/smesguiche/bike_counters_Samuel/data/test.parquet"))


data_test


import problem

X_train, y_train = problem.get_train_data()
X_test, y_test = problem.get_test_data()


X_train





y_train





print(
    f'Train: n_samples={X_train.shape[0]},  {X_train["date"].min()} to {X_train["date"].max()}'
)
print(
    f'Test: n_samples={X_test.shape[0]},  {X_test["date"].min()} to {X_test["date"].max()}'
)


_encode_dates(X_train[["date"]]).columns.tolist()


from sklearn.compose import ColumnTransformer
from sklearn.linear_model import Ridge
from sklearn.pipeline import make_pipeline

date_encoder = FunctionTransformer(_encode_dates)
date_cols = _encode_dates(X_train[["date"]]).columns.tolist()

categorical_encoder = OneHotEncoder(handle_unknown="ignore")
categorical_cols = ["counter_name", "site_name"]

preprocessor = ColumnTransformer(
    [
        ("date", OneHotEncoder(handle_unknown="ignore"), date_cols),
        ("cat", categorical_encoder, categorical_cols),
    ]
)

regressor = Ridge()

pipe = make_pipeline(date_encoder, preprocessor, regressor)
pipe.fit(X_train, y_train)





from sklearn.metrics import mean_squared_error

print(
    f"Train set, RMSE={mean_squared_error(y_train, pipe.predict(X_train), squared=False):.2f}"
)
print(
    f"Test set, RMSE={mean_squared_error(y_test, pipe.predict(X_test), squared=False):.2f}"
)





print("Baseline mean prediction.")
print(
    f"Train set, RMSE={mean_squared_error(y_train, np.full(y_train.shape, y_train.mean()), squared=False):.2f}"
)
print(
    f"Test set, RMSE={mean_squared_error(y_test, np.full(y_test.shape, y_test.mean()), squared=False):.2f}"
)





mask = (
    (X_test["counter_name"] == "Totem 73 boulevard de Sébastopol S-N")
    & (X_test["date"] > pd.to_datetime("2021/09/01"))
    & (X_test["date"] < pd.to_datetime("2021/09/08"))
)

df_viz = X_test.loc[mask].copy()
df_viz["bike_count"] = np.exp(y_test[mask.values]) - 1
df_viz["bike_count (predicted)"] = np.exp(pipe.predict(X_test[mask])) - 1


fig, ax = plt.subplots(figsize=(12, 4))

df_viz.plot(x="date", y="bike_count", ax=ax)
df_viz.plot(x="date", y="bike_count (predicted)", ax=ax, ls="--")
ax.set_title("Predictions with Ridge")
ax.set_ylabel("bike_count")





fig, ax = plt.subplots()

df_viz = pd.DataFrame({"y_true": y_test, "y_pred": pipe.predict(X_test)}).sample(
    10000, random_state=0
)

df_viz.plot.scatter(x="y_true", y="y_pred", s=8, alpha=0.1, ax=ax)





from sklearn.model_selection import TimeSeriesSplit, cross_val_score

cv = TimeSeriesSplit(n_splits=6)

# When using a scorer in scikit-learn it always needs to be better when smaller, hence the minus sign.
scores = cross_val_score(
    pipe, X_train, y_train, cv=cv, scoring="neg_root_mean_squared_error"
)
print("RMSE: ", scores)
print(f"RMSE (all folds): {-scores.mean():.3} ± {(-scores).std():.3}")


y_pred = pipe.predict(X_test)
results = pd.DataFrame(
    dict(
        Id=np.arange(y_pred.shape[0]),
        log_bike_count=y_pred,
    )
)
results.to_csv("submission.csv", index=False)



